{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY7Z0yjSgPy4"
      },
      "source": [
        "# Exercise 1: PCA, ICA and Sparse Coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7OBjTKfgPy5"
      },
      "source": [
        "**Note**: Please insert the names of all participating students:\n",
        "\n",
        "1. Marten Buchmann\n",
        "2. Carl Gathmann"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeiLqMsHgPy5"
      },
      "source": [
        "## Preamble\n",
        "The following code downloads and imports all necessary files and modules into the virtual machine of Colab. Please make sure to execute it before solving this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QsEOmiEtgPy5",
        "outputId": "151b6479-5b9a-40ef-e50c-ec6ee0df2cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs5450'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 124 (delta 37), reused 29 (delta 13), pack-reused 61 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 27.57 MiB | 17.63 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "  if os.getcwd() == '/content':\n",
        "    !git clone 'https://github.com/inb-luebeck/cs5450.git'\n",
        "    os.chdir('cs5450')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K9TLw30gPy6"
      },
      "source": [
        "## Exercise 1.1: Applying unsupervised methods\n",
        "\n",
        "In this exercise, we will apply three unsupervised methods, namely *Principal Component Analysis (PCA)*, *Independent Component Analysis (ICA)*, and *Sparse Coding (SC)* to image patches taken from handwriting digits and faces.\n",
        "\n",
        "Since implementing [ICA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html) and [SC](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparseCoder.html) is rather complex, we will use already existing python packages.\n",
        "\n",
        "We will build on the python starter code given below. You only need to write code at the places indicated by `TODO`.\n",
        "The two given datasets are `mnist.npz` for handwritten digits and `olivetti.npz` for faces. Each dataset contains a multi-dimensional array `data` with the first index corresponding to the observations and the second index corresponding to the features (grayscale pixels). Both datasets contain square-shaped images.\n",
        "\n",
        "Implement the missing parts below. When done correctly, your code should do the following:\n",
        "1. Load the dataset with either handwritten images or faces.\n",
        "2. Enforce mean-free observations by subtracting the mean from the data.\n",
        "3. Randomly draw square-shaped image patches from the data.\n",
        "4. Apply one of the three unsupervised methods (PCA, ICA, or SC).\n",
        "5. Show the resulting set of new basis vectors (i.e., the components for PCA and ICA).\n",
        "6. Reconstruct the original image patches with different subsets of basis vectors.\n",
        "\n",
        "Note that for sparse coding, the basis vectors are not ordered according to some metric (*unlike which method?*). To quickly reconstruct an image with only $i$ non-zero values, you should use the coefficients and basis vectors corresponding to the $i$ highest absolute coefficients (see [numpy.argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)).\n",
        "\n",
        "In case you are struggeling with the task, here are some helpful tips and hints:\n",
        "1. Useful functions: [`numpy.load`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html), [`ndarray.astype`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.astype.html), [`numpy.mean`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html), [`numpy.linalg.pinv`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.pinv.html), [`numpy.matmul`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html), [`numpy.stack`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html), `random_patches`, `show_in_grid`, [`PCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), [`FastICA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html#sklearn.decomposition.FastICA), [`DictionaryLearning`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.DictionaryLearning.html#sklearn.decomposition.DictionaryLearning),[`numpy.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)\n",
        "2. **Complete the basis computation and reconstruction for PCA first.**\n",
        "3. To obtain the coefficients $\\vec{x}_{pca}$ and $\\vec{x}_{ica}$, only matrix multiplication is needed. Use \"sparse_encode\" to obtain $\\vec{x}_{sc}$\n",
        "4. Since learning a sparse coding dictionary can take a long time, we provide a pre-computed basis at \"data/sc_basis.npy\" that you only need to load. **Note that the pre-computed basis only works with MNIST and a patch-size of 25!**\n",
        "As a starting point you can use the following initial values:\n",
        "- `dataset=\"mnist\"`\n",
        "- `n_patches=10000`\n",
        "- `patch_size=25`\n",
        "- `n_basis=100`\n",
        "\n",
        "And for Sparse Coding also:\n",
        "- `n_iterations=50`\n",
        "- `n_jobs=-1` and\n",
        "- `verbose=True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um6L9GVWgPy6"
      },
      "source": [
        "Import and helper functions. Do not change!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": false,
        "id": "7-xzEZM-gPy6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from sklearn.decomposition import PCA, FastICA, DictionaryLearning\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def random_patches(data, img_height, img_width, n_patches, patch_size):\n",
        "    # RANDOMPATCHES draw random square-shaped patches from the data.\n",
        "    #\n",
        "    # INPUT:\n",
        "    #   data : ndarray containing the data (i.e. mnist or olivetti)\n",
        "    #   img_height : height of the images\n",
        "    #   img_width : width of the images\n",
        "    #   n_patches : number of patches to be drawn\n",
        "    #   patch_size : size (both width and height) of the square-shaped patches\n",
        "    #\n",
        "    # OUTPUT:\n",
        "    #   patches : random patches\n",
        "\n",
        "    # reshape data 2d -> 3d\n",
        "    n_images = data.shape[0]\n",
        "    data = data.reshape(n_images, img_height, img_width)\n",
        "\n",
        "    # extract random patches\n",
        "    patches = []#np.zeros((n_patches, patch_size*patch_size))\n",
        "    for i in range(n_patches):\n",
        "        patch_top = random.randint(0, img_height - patch_size)\n",
        "        patch_left = random.randint(0, img_width - patch_size)\n",
        "        p = data[random.randint(0, n_images-1), patch_top:patch_top+patch_size, patch_left:patch_left+patch_size]\n",
        "        patches.append(p)\n",
        "        #patches[i,:] = p[:]\n",
        "\n",
        "    patches = np.stack(patches)\n",
        "    patches = patches.reshape(patches.shape[0], -1) #flatten each patch\n",
        "\n",
        "    return patches\n",
        "\n",
        "def show_in_grid(images, height, width):\n",
        "    # flatten images if necessary\n",
        "    images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "    # normalize patches\n",
        "    images = images / (np.abs(images).max(axis=1, keepdims=True)+1e-6)\n",
        "\n",
        "    # reshape into images\n",
        "    images = images.reshape(-1, height, width)\n",
        "\n",
        "    # make images fit into a rectangular area\n",
        "    grid_width = math.ceil(math.sqrt(images.shape[0]))\n",
        "    grid_height = math.ceil(images.shape[0] / grid_width)\n",
        "\n",
        "    empty_cells = grid_width * grid_height - images.shape[0]\n",
        "\n",
        "    # fill empty cells\n",
        "    if empty_cells > 0:\n",
        "        padding = np.zeros((empty_cells, height, width))\n",
        "        images = np.concatenate((images, padding))\n",
        "\n",
        "    # rearrange basis into grid and also switch width and height so x and y axis are not switched\n",
        "    images = images.reshape(grid_height, grid_width, height, width)\n",
        "    images = images.transpose(0, 3, 1, 2)\n",
        "\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.imshow(images.reshape(grid_height*height, grid_width*width), cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jioz9SgKgPy6"
      },
      "source": [
        "Your solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OBKO6m_bgPy6"
      },
      "outputs": [],
      "source": [
        "## Define variables\n",
        "\n",
        "# TODO dataset : relative path to the .npz file containing the data\n",
        "dataset = 'data/olivetti.npz' #'data/olivetti.npz'\n",
        "\n",
        "# TODO n_patches : number of random patches to extract from the images\n",
        "n_patches = 30\n",
        "# TODO patch_size : size (both width and height) of the square-shaped patches\n",
        "patch_size = 30\n",
        "\n",
        "# TODO n_basis : number of new basis vectors\n",
        "n_basis = 5\n",
        "\n",
        "# TODO method : string describing whether to perform pca, ica, or sc\n",
        "method = 'pca'\n",
        "\n",
        "# TODO n_iterations : number of iterations (only for sparse coding)\n",
        "n_iterations = -1\n",
        "\n",
        "SC_LOAD_DICTIONARY = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Falz3ogPy6",
        "outputId": "60193cab-4185-42a4-eddb-e409351591cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 900)\n"
          ]
        }
      ],
      "source": [
        "## Compute and show the principal components\n",
        "\n",
        "# TODO load dataset\n",
        "data = np.load(dataset)['data']\n",
        "\n",
        "# TODO convert data to floating point (double precision)\n",
        "data = data.astype(np.float64)\n",
        "\n",
        "# TODO get number of images (observations) and number of pixels (features)\n",
        "n_images, n_pixels = data.shape\n",
        "\n",
        "# TODO get height and width of the images\n",
        "img_height = int(np.sqrt(n_pixels))\n",
        "img_width = int(np.sqrt(n_pixels))\n",
        "assert isinstance(img_height, int) and isinstance(img_width, int), \"Image dimensions need to be integers.\"\n",
        "\n",
        "# TODO enforce mean-free data vectors\n",
        "mean_free_data = data - np.mean(data, axis=0)\n",
        "\n",
        "# TODO draw random patches from data.\n",
        "rand_patches = random_patches(mean_free_data, img_height, img_width, n_patches, patch_size)\n",
        "# show_in_grid(rand_patches, patch_size, patch_size)\n",
        "\n",
        "# TODO perform the chosen unsupervised method on the drawn patches\n",
        "if method == 'pca':\n",
        "    x_pca = PCA(n_components=n_basis).fit(rand_patches)\n",
        "    basis = x_pca.components_\n",
        "    # basis = basis.reshape(n_basis, patch_size, patch_size)\n",
        "    print(basis.shape)\n",
        "elif method == 'ica':\n",
        "    basis = -1\n",
        "elif method == 'sc':\n",
        "    if SC_LOAD_DICTIONARY:\n",
        "        basis = -1\n",
        "    else:\n",
        "        basis = -1\n",
        "\n",
        "# TODO show the new set of basis vectors (only the first n_basis)\n",
        "# show_in_grid(basis[:n_basis], patch_size, patch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMYP3f75gPy7",
        "outputId": "277fe3d8-7acb-4267-b1c4-4caa175e1be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 900)\n",
            "(1, 900)\n",
            "(2, 900)\n",
            "(3, 900)\n",
            "(4, 900)\n"
          ]
        }
      ],
      "source": [
        "# RECONSTRUCTION\n",
        "## Use different subsets of the new basis vectors to reconstruct a random patch\n",
        "## This is meant to visualize how including more and more basis vectors increases the information content of the reconstructed image\n",
        "from sklearn.decomposition import sparse_encode\n",
        "\n",
        "# TODO draw a random patch\n",
        "random_patch = rand_patches[random.randint(0, n_patches-1)]\n",
        "# show_in_grid(random_patch, patch_size, patch_size)\n",
        "\n",
        "# TODO reconstruct the random patch\n",
        "reconstructions = [basis[0]]\n",
        "\n",
        "def sparse_coding_reconstruction(random_patch, basis, reconstructions, n_basis):\n",
        "    for i in range(n_basis):\n",
        "        # TODO: only use the first i basis vectors\n",
        "        # TODO: compute the coefficients\n",
        "        # From sparse_encode documentation. The output of sparse_encode\n",
        "        # X ~= code * dictionary\n",
        "        coef = -1\n",
        "        # TODO: compute the reconstruction\n",
        "        x_recon = -1\n",
        "        reconstructions.append(x_recon)\n",
        "\n",
        "    return reconstructions\n",
        "\n",
        "def linear_reconstruction(random_patch, basis, reconstructions, n_basis):\n",
        "    for i in range(n_basis):\n",
        "        # TODO: only use the first i basis vectors\n",
        "        basis_i = basis[:i]\n",
        "        # TODO: compute the inverse basis\n",
        "        basis_i_inv = np.linalg.pinv(basis_i)\n",
        "        # TODO: compute the coefficients\n",
        "        coef = np.matmul(random_patch, basis_i_inv)\n",
        "        # TODO: compute the reconstruction\n",
        "        x_recon = np.matmul(coef, basis_i)\n",
        "        reconstructions.append(x_recon)\n",
        "\n",
        "    return reconstructions\n",
        "\n",
        "if method == 'sc':\n",
        "    reconstructions = sparse_coding_reconstruction(\n",
        "        random_patch, basis, reconstructions, n_basis\n",
        "    )\n",
        "else:\n",
        "    reconstructions = linear_reconstruction(\n",
        "        random_patch, basis, reconstructions, n_basis\n",
        "    )\n",
        "reconstructions = np.stack(reconstructions)\n",
        "\n",
        "# TODO show the reconstructed patch\n",
        "# show_in_grid(reconstructions, patch_size, patch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDHeynyfgPy7"
      },
      "source": [
        "*Bonus*: Implement the missing parts in the bonus section. When done correctly, your code additionally should do the following:\n",
        "1. Perform ZCA whitening, whereas $\\vec{x}_{ZCAwhite}=U\\vec{x}_{wht}$ (c.f. equation 1.3 in the lecture notes).\n",
        "2. Visualize the whitened data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjcwipMggPy7"
      },
      "outputs": [],
      "source": [
        "#% TODO epsilon : avoid negative numbers while computing stdDeviations\n",
        "epsilon = 0.1\n",
        "\n",
        "# TODO perform principal component analysis (help pca)\n",
        "# basis = -1 #get basis vector components\n",
        "\n",
        "# TODO compute the covariance matrix of the patches\n",
        "covariance = -1\n",
        "\n",
        "# TODO compute diagonal matrix S containing the standard deviations (c.f. page 6)\n",
        "std_deviations = -1\n",
        "\n",
        "# TODO pca whitening (c.f. equation 1.3)\n",
        "xPCAwhite = -1\n",
        "\n",
        "# TODO zca whitening\n",
        "xZCAwhite = -1\n",
        "\n",
        "# TODO visualize the whitened data\n",
        "# show_in_grid(xZCAwhite[:n_basis], patch_size, patch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9etNquj9gPy7"
      },
      "source": [
        "## Exercise 1.2: Comprehension Questions\n",
        "\n",
        "Answer the following comprehension questions either with *right* or *wrong* and briefly explain your decision:\n",
        "1. Regardless of the used method for representation learning (i.e. PCA, ICA, SC), the resulting set of basis vectors depends on the given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8tz3cXGgPy7"
      },
      "source": [
        "[Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pEU3kehgPy7"
      },
      "source": [
        "2. The first principal component has the smallest eigenvalue and covers the largest possible variance of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeABtk1FgPy7"
      },
      "source": [
        "[Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYsmhYaogPy7"
      },
      "source": [
        "3. The optimal number of principal components to retain is 42."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2SSq38GgPy7"
      },
      "source": [
        " [Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEUs78ksgPy7"
      },
      "source": [
        "4. After whitening, the features of an observation are uncorrelated and have unit variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Qv31A1gPy7"
      },
      "source": [
        "[Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_7sjbaNgPy7"
      },
      "source": [
        "5. The resulting basis vectors of the ICA (i.e. the independent components) are mutually orthogonal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kUrOGYxgPy7"
      },
      "source": [
        " [Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIU_tyo4gPy7"
      },
      "source": [
        "6. The ICA is an enhancement of the PCA which additionally aims to make the already uncorrelated features statistically independent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsFfa0r0gPy7"
      },
      "source": [
        " [Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laGHSmNcgPy7"
      },
      "source": [
        "7. The set of basis vectors of the ICA can be over-complete, i.e. more basis vectors than dimensions of the input space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVtJLTFzgPy7"
      },
      "source": [
        " [Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOdGEBd8gPy7"
      },
      "source": [
        "8. Sparsity means that only a few basis vectors are used to reconstruct an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1s9QAgdgPy7"
      },
      "source": [
        " [Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceqFdTo2gPy7"
      },
      "source": [
        "9. The optimization problem for SC (c.f. equation 1.9 in the lecture notes) is convex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dG5dv8jgPy7"
      },
      "source": [
        "[Your answer]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAP8_IS9gPy7"
      },
      "source": [
        "10. Unlike PCA and ICA, SC results in a linear transform of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-3R1EIygPy8"
      },
      "source": [
        "[Your answer]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}